{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Resnet34","metadata":{}},{"cell_type":"markdown","source":"## Import the required libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import OrderedDict\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:12.756124Z","iopub.execute_input":"2025-01-27T14:29:12.756464Z","iopub.status.idle":"2025-01-27T14:29:17.049127Z","shell.execute_reply.started":"2025-01-27T14:29:12.756426Z","shell.execute_reply":"2025-01-27T14:29:17.048211Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Set device to CUDA\n\nIf our system supports GPU, we can accelerate the training and testing greatly by utilizing graphics cards.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:17.050906Z","iopub.execute_input":"2025-01-27T14:29:17.051836Z","iopub.status.idle":"2025-01-27T14:29:17.091109Z","shell.execute_reply.started":"2025-01-27T14:29:17.051807Z","shell.execute_reply":"2025-01-27T14:29:17.090314Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Let's define the building block of the model\n\n\n### Why the downsample condition block?\n\nIn the code below, we defined the downsample block first as not layers have it.\n\nThe resnet starts with an initialization block, followed by 4 layers, each of which consisting of sub layers. Only each of the beginning layers consists of the downsample function.\n\n### Common layers\n\nThen we have defined the common layers in the model. The sequence is as follows:\n1. Conv layer of kernel size 3\n2. Batch Normalization\n3. ReLU activation function\n4. Conv layer of kernel size 3\n5. Batch Normalization\n6. (optional) Downsampling\n\n### Hyperparameters\n\nThere parameters aren't modified during training. I have set them as per the implementation used in resnet34 version imported from torchvision.","metadata":{}},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_c, out_c, stride=1, downsample=False):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        if downsample != False:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False),\n                nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n        \n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample != None:\n            x = self.downsample(x)\n        \n        out += x\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:17.454770Z","iopub.execute_input":"2025-01-27T14:29:17.455080Z","iopub.status.idle":"2025-01-27T14:29:17.462363Z","shell.execute_reply.started":"2025-01-27T14:29:17.455054Z","shell.execute_reply":"2025-01-27T14:29:17.461469Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Let's define the resnet34\n\n### First we define the initial layers\n\nThe initial layers consist of:\n1. Conv layer 1 of kernel size 7\n2. Batch Normalization\n3. ReLU Activation function\n4. Max Pooling layer\n\n### Define a function _make_layers\n\nWe define a dictionary where we keep adding layers by calling the block class. We then return them as a sequence of layers.\n\n### Stack all the layers\n\nWe then stack all the layers. Now our model is ready.","metadata":{}},{"cell_type":"code","source":"class resnet34(nn.Module):\n    def __init__(self, out_class):\n        super().__init__()\n\n        self.out_class = out_class\n        \n        self.initial = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(in_features=512, out_features=self.out_class, bias=True)\n        \n        self.layer_count = [3, 4, 6, 3]\n        self.channels = [64, 64, 128, 256, 512]\n\n        self.layer_1 = self._make_layers(0)\n        self.layer_2 = self._make_layers(1, True)\n        self.layer_3 = self._make_layers(2, True)\n        self.layer_4 = self._make_layers(3, True)\n        \n    def _make_layers(self, c, first=False):\n        layers = OrderedDict()\n        \n        for i in range(self.layer_count[c]):\n            if first==True:\n                x = c\n                downsample = True\n                stride=2\n            else:\n                x = c+1\n                downsample = False\n                stride=1\n            layers[f'sub_layer_{i}'] = (Block(self.channels[x], self.channels[c+1], stride=stride, downsample=downsample))\n            first = False\n\n        return nn.Sequential(layers)\n        \n    def forward(self, x):\n        x = self.initial(x)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n        x = self.layer_3(x)\n        x = self.layer_4(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)       \n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:20.527200Z","iopub.execute_input":"2025-01-27T14:29:20.527659Z","iopub.status.idle":"2025-01-27T14:29:20.536770Z","shell.execute_reply.started":"2025-01-27T14:29:20.527622Z","shell.execute_reply":"2025-01-27T14:29:20.535754Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Let's test our code on a dataset\n\n### Let's load our data\nWe will work on the MNIST dataset by importing it from the torchvision library. We will divide the training dataset for training and validations purposes in the 7:3 ratio.\nWe also apply transforms to our data, by resizing the data to size 224x224. Then the most important part, converting images to a tensor to make it usable for training and testing purposes.","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.MNIST(\n    root='./data',\n    train=True,\n    download=True,\n    transform=transform,\n)\n\ntest_dataset = datasets.MNIST(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform,\n)\n\ntrain_original_size = len(train_dataset)\ntrain_size = int(0.7 * train_original_size)\nval_size = int(0.3 * train_original_size)\n\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:23.359337Z","iopub.execute_input":"2025-01-27T14:29:23.359692Z","iopub.status.idle":"2025-01-27T14:29:25.027870Z","shell.execute_reply.started":"2025-01-27T14:29:23.359661Z","shell.execute_reply":"2025-01-27T14:29:25.027054Z"}},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 59592998.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 1581860.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 14115302.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\n<urlopen error [Errno 111] Connection refused>\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2800312.92it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Training and testing\n\nNow we are ready to train and test our dataset","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    model = resnet34(10).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='abs')\n\n    num_epochs = 20\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0\n        correct_predictions = 0\n        total_samples = 0\n\n        with tqdm(total=len(train_loader), desc=f\"Epoch: {epoch}/{num_epochs}\", unit=\"batch\") as pbar:\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                correct_predictions += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n\n                pbar.set_postfix(loss=loss.item())\n                pbar.update(1)\n\n            avg_loss = running_loss / len(train_loader)\n            train_accuracy = 100 * correct_predictions / total_samples\n\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                val_correct += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n\n        avg_val_loss = val_loss / len(val_loader)\n        val_accuracy = 100 * val_correct / val_total\n\n        scheduler.step(avg_val_loss)  # Adjust learning rate based on validation loss\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T14:29:31.160834Z","iopub.execute_input":"2025-01-27T14:29:31.161164Z"}},"outputs":[{"name":"stderr","text":"Epoch: 0/20:  63%|██████▎   | 828/1313 [01:27<00:50,  9.53batch/s, loss=0.0273] ","output_type":"stream"}],"execution_count":null}]}