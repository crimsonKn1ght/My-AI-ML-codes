{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Resnet34","metadata":{}},{"cell_type":"markdown","source":"## Import the required libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import OrderedDict\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:39:27.793723Z","iopub.execute_input":"2025-01-14T14:39:27.794102Z","iopub.status.idle":"2025-01-14T14:39:31.954017Z","shell.execute_reply.started":"2025-01-14T14:39:27.794046Z","shell.execute_reply":"2025-01-14T14:39:31.953093Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Set device to CUDA\n\nIf our system supports GPU, we can accelerate the training and testing greatly by utilizing graphics cards.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:39:31.956227Z","iopub.execute_input":"2025-01-14T14:39:31.956987Z","iopub.status.idle":"2025-01-14T14:39:31.990844Z","shell.execute_reply.started":"2025-01-14T14:39:31.956946Z","shell.execute_reply":"2025-01-14T14:39:31.989950Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Let's define the building block of the model\n\n\n### Why the downsample condition block?\n\nIn the code below, we defined the downsample block first as not layers have it.\n\nThe resnet starts with an initialization block, followed by 4 layers, each of which consisting of sub layers. Only each of the beginning layers consists of the downsample function.\n\n### Common layers\n\nThen we have defined the common layers in the model. The sequence is as follows:\n1. Conv layer of kernel size 3\n2. Batch Normalization\n3. ReLU activation function\n4. Conv layer of kernel size 3\n5. Batch Normalization\n6. (optional) Downsampling\n\n### Hyperparameters\n\nThere parameters aren't modified during training. I have set them as per the implementation used in resnet34 version imported from torchvision.","metadata":{}},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_c, out_c, stride=1, downsample=False):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n\n        if downsample != False:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False),\n                nn.BatchNorm2d(out_c, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n        \n        else:\n            self.downsample = None\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample != None:\n            i = self.downsample(x)\n            out += i\n\n        return out\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:39:31.991820Z","iopub.execute_input":"2025-01-14T14:39:31.992058Z","iopub.status.idle":"2025-01-14T14:39:32.006763Z","shell.execute_reply.started":"2025-01-14T14:39:31.992035Z","shell.execute_reply":"2025-01-14T14:39:32.006005Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Let's define the resnet34\n\n### First we define the initial layers\n\nThe initial layers consist of:\n1. Conv layer 1 of kernel size 7\n2. Batch Normalization\n3. ReLU Activation function\n4. Max Pooling layer\n\n### Define a function _make_layers\n\nWe define a dictionary where we keep adding layers by calling the block class. We then return them as a sequence of layers.\n\n### Stack all the layers\n\nWe then stack all the layers. Now our model is ready.","metadata":{}},{"cell_type":"code","source":"class resnet34(nn.Module):\n    def __init__(self, out_class):\n        super().__init__()\n\n        self.out_class = out_class\n        \n        self.initial = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(in_features=512, out_features=self.out_class, bias=True)\n        \n        self.layer_count = [3, 4, 6, 3]\n        self.channels = [64, 64, 128, 256, 512]\n\n        self.layer_1 = self._make_layers(0)\n        self.layer_2 = self._make_layers(1, True)\n        self.layer_3 = self._make_layers(2, True)\n        self.layer_4 = self._make_layers(3, True)\n        \n    def _make_layers(self, c, first=False):\n        layers = OrderedDict()\n        \n        for i in range(self.layer_count[c]):\n            if first==True:\n                x = c\n                downsample = True\n                stride=2\n            else:\n                x = c+1\n                downsample = False\n                stride=1\n            layers[f'sub_layer_{i}'] = (Block(self.channels[x], self.channels[c+1], stride=stride, downsample=downsample))\n            first = False\n\n        return nn.Sequential(layers)\n        \n    def forward(self, x):\n        x = self.initial(x)\n        x = self.layer_1(x)\n        x = self.layer_2(x)\n        x = self.layer_3(x)\n        x = self.layer_4(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)       \n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T15:01:13.098192Z","iopub.execute_input":"2025-01-14T15:01:13.098767Z","iopub.status.idle":"2025-01-14T15:01:13.109052Z","shell.execute_reply.started":"2025-01-14T15:01:13.098735Z","shell.execute_reply":"2025-01-14T15:01:13.108115Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Let's test our code on a dataset\n\n### Let's load our data\nWe will work on the MNIST dataset by importing it from the torchvision library. We will divide the training dataset for training and validations purposes in the 7:3 ratio.\nWe also apply transforms to our data, by resizing the data to size 224x224. Then the most important part, converting images to a tensor to make it usable for training and testing purposes.","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = datasets.MNIST(\n    root='./data',\n    train=True,\n    download=True,\n    transform=transform,\n)\n\ntest_dataset = datasets.MNIST(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transform,\n)\n\ntrain_original_size = len(train_dataset)\ntrain_size = int(0.7 * train_original_size)\nval_size = int(0.3 * train_original_size)\n\ntrain_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:39:36.522813Z","iopub.execute_input":"2025-01-14T14:39:36.523626Z","iopub.status.idle":"2025-01-14T14:39:43.110476Z","shell.execute_reply.started":"2025-01-14T14:39:36.523587Z","shell.execute_reply":"2025-01-14T14:39:43.109552Z"}},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 12722680.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 337187.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 3189851.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2332337.02it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Training and testing\n\nNow we are ready to train and test our dataset","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    model = resnet34(10).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='abs')\n\n    num_epochs = 20\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0\n        correct_predictions = 0\n        total_samples = 0\n\n        with tqdm(total=len(train_loader), desc=f\"Epoch: {epoch}/{num_epochs}\", unit=\"batch\") as pbar:\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                correct_predictions += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n\n                pbar.set_postfix(loss=loss.item())\n                pbar.update(1)\n\n            avg_loss = running_loss / len(train_loader)\n            train_accuracy = 100 * correct_predictions / total_samples\n\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                val_correct += (predicted == labels).sum().item()\n                val_total += labels.size(0)\n\n        avg_val_loss = val_loss / len(val_loader)\n        val_accuracy = 100 * val_correct / val_total\n\n        scheduler.step(avg_val_loss)  # Adjust learning rate based on validation loss\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T14:39:46.715841Z","iopub.execute_input":"2025-01-14T14:39:46.716661Z","iopub.status.idle":"2025-01-14T15:01:08.039754Z","shell.execute_reply.started":"2025-01-14T14:39:46.716617Z","shell.execute_reply":"2025-01-14T15:01:08.038626Z"}},"outputs":[{"name":"stderr","text":"Epoch: 0/20: 100%|██████████| 1313/1313 [02:16<00:00,  9.59batch/s, loss=0.0447] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20], Train Loss: 0.1455, Train Acc: 95.62%, Val Loss: 0.0750, Val Acc: 97.77%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 1/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.67batch/s, loss=0.0453] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20], Train Loss: 0.0580, Train Acc: 98.27%, Val Loss: 0.0575, Val Acc: 98.24%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 2/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.66batch/s, loss=0.0149] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20], Train Loss: 0.0524, Train Acc: 98.43%, Val Loss: 0.0459, Val Acc: 98.62%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 3/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.66batch/s, loss=0.0666] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20], Train Loss: 0.0470, Train Acc: 98.55%, Val Loss: 0.0775, Val Acc: 97.58%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 4/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.67batch/s, loss=0.0257]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/20], Train Loss: 0.0421, Train Acc: 98.72%, Val Loss: 0.0409, Val Acc: 98.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 5/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.68batch/s, loss=0.00294] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/20], Train Loss: 0.0365, Train Acc: 98.88%, Val Loss: 0.0315, Val Acc: 99.07%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 6/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.67batch/s, loss=0.0257]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/20], Train Loss: 0.0343, Train Acc: 98.91%, Val Loss: 0.0529, Val Acc: 98.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 7/20: 100%|██████████| 1313/1313 [02:15<00:00,  9.67batch/s, loss=0.0191]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/20], Train Loss: 0.0327, Train Acc: 99.02%, Val Loss: 0.0322, Val Acc: 99.09%\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 8/20:  16%|█▌        | 207/1313 [00:21<01:55,  9.60batch/s, loss=0.00144] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"from torchvision.models import resnet34\n\nmodel = resnet34()\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T13:57:20.351537Z","iopub.execute_input":"2025-01-14T13:57:20.351973Z","iopub.status.idle":"2025-01-14T13:57:20.731149Z","shell.execute_reply.started":"2025-01-14T13:57:20.351928Z","shell.execute_reply":"2025-01-14T13:57:20.729756Z"}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}